{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Data manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Machine learning model from scikit-learn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# To ignore warnings (optional)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install pandas_ta\n",
        "import pandas as pd\n",
        "import pandas_ta as ta  # Make sure you have installed pandas_ta (pip install pandas_ta)\n",
        "\n",
        "# Import necessary libraries and metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo4wuVD8a86u",
        "outputId": "572c4379-0de3-4bb8-fede-9f793e3a8e15"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pandas_ta) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.17.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218909 sha256=57176861c3de648c99988489662667560a74a03ba44f5fb148eff9807f2c14d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/33/8b/50b245c5c65433cd8f5cb24ac15d97e5a3db2d41a8b6ae957d\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'crypto_data.csv' with the actual filename\n",
        "df = pd.read_csv('crypto_data.csv')\n",
        "# df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YsDNrmR7dFXu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_crypto_df(df):\n",
        "    \"\"\"\n",
        "    Preprocess the cryptocurrency DataFrame.\n",
        "\n",
        "    Expected DataFrame columns:\n",
        "    - 'Time': String in the format \"dd-mm-yyyy HH:MM\" (e.g., \"01-01-2018 00:00\")\n",
        "    - 'Open', 'High', 'Low', 'Close', 'Volume': Numeric values as strings or numbers.\n",
        "\n",
        "    The function will:\n",
        "    - Convert the 'Time' column to a datetime object.\n",
        "    - Drop rows with invalid dates.\n",
        "    - Set 'Time' as the DataFrame index.\n",
        "    - Ensure the numeric columns are in a proper numeric format.\n",
        "    - Drop rows with missing values in numeric columns.\n",
        "    - Sort the DataFrame by time.\n",
        "\n",
        "    Returns:\n",
        "        A cleaned and preprocessed DataFrame.\n",
        "    \"\"\"\n",
        "\n",
        "    # Make a copy of the DataFrame to avoid modifying the original data\n",
        "    df = df.copy()\n",
        "\n",
        "    # Convert 'Time' column to datetime using the expected format\n",
        "    # errors='coerce' will convert any invalid parsing into NaT (Not a Time)\n",
        "    df['Time'] = pd.to_datetime(df['Time'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
        "\n",
        "    # Drop any rows where 'Time' conversion failed (i.e., contains NaT)\n",
        "    df.dropna(subset=['Time'], inplace=True)\n",
        "\n",
        "    # Set the 'Time' column as the index of the DataFrame\n",
        "    df.set_index('Time', inplace=True)\n",
        "\n",
        "    # List of columns expected to be numeric\n",
        "    numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "\n",
        "    # Convert each numeric column to a proper numeric type\n",
        "    # errors='coerce' will set any non-convertible values to NaN\n",
        "    for col in numeric_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Drop rows that have any missing values in the numeric columns\n",
        "    df.dropna(subset=numeric_cols, inplace=True)\n",
        "\n",
        "    # Sort the DataFrame by the time index to ensure chronological order\n",
        "    df.sort_index(inplace=True)\n",
        "\n",
        "    # Return the cleaned and preprocessed DataFrame\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "OcflcbLhdlOK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_technical_features(df):\n",
        "    \"\"\"\n",
        "    Adds technical indicators and features from the pandas_ta library to the DataFrame.\n",
        "\n",
        "    The function assumes the DataFrame contains the following columns:\n",
        "      - 'Open'\n",
        "      - 'High'\n",
        "      - 'Low'\n",
        "      - 'Close'\n",
        "      - 'Volume'\n",
        "\n",
        "    It will add:\n",
        "      - Multiple EMAs for periods: 5, 20, 45, 50, 100, 200.\n",
        "      - RSI (Relative Strength Index) with a default period of 14.\n",
        "      - MACD (Moving Average Convergence Divergence) along with its histogram and signal.\n",
        "      - Bollinger Bands (Lower, Middle, and Upper bands).\n",
        "      - Stochastic Oscillator.\n",
        "      - ATR (Average True Range) with a period of 14.\n",
        "      - 'Next_Close': The closing price of the next candle (target for prediction).\n",
        "\n",
        "    Finally, it drops any rows with missing values (e.g., at the beginning or end due to shifting/rolling calculations).\n",
        "\n",
        "    Parameters:\n",
        "      df (pd.DataFrame): Input DataFrame containing crypto price data.\n",
        "\n",
        "    Returns:\n",
        "      pd.DataFrame: DataFrame enriched with new technical features.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a copy of the DataFrame to avoid modifying the original data\n",
        "    df = df.copy()\n",
        "\n",
        "    # ------------------------------\n",
        "    # Add Multiple Exponential Moving Averages (EMAs)\n",
        "    # ------------------------------\n",
        "    ema_periods = [5, 20, 45, 50, 100, 200]\n",
        "    for period in ema_periods:\n",
        "        # Calculate EMA for the given period and add as a new column, e.g., 'EMA_5'\n",
        "        df[f'EMA_{period}'] = ta.ema(df['Close'], length=period)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Add Relative Strength Index (RSI)\n",
        "    # ------------------------------\n",
        "    # Default period for RSI is 14\n",
        "    df['RSI'] = ta.rsi(df['Close'], length=14)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Add MACD (Moving Average Convergence Divergence)\n",
        "    # ------------------------------\n",
        "    # MACD returns a DataFrame with columns: MACD, MACDh (histogram), and MACDs (signal)\n",
        "    macd_df = ta.macd(df['Close'])\n",
        "    # Concatenate the MACD columns with the main DataFrame\n",
        "    df = pd.concat([df, macd_df], axis=1)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Add Bollinger Bands\n",
        "    # ------------------------------\n",
        "    # Bollinger Bands returns a DataFrame with lower band (BBL), middle band (BBM), upper band (BBU), etc.\n",
        "    bbands_df = ta.bbands(df['Close'], length=20, std=2)\n",
        "    df = pd.concat([df, bbands_df], axis=1)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Add Stochastic Oscillator\n",
        "    # ------------------------------\n",
        "    # Using high, low, and close prices. Returns %K and %D values.\n",
        "    stoch_df = ta.stoch(df['High'], df['Low'], df['Close'])\n",
        "    df = pd.concat([df, stoch_df], axis=1)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Add Average True Range (ATR)\n",
        "    # ------------------------------\n",
        "    # ATR is computed over a period of 14 by default.\n",
        "    df['ATR'] = ta.atr(df['High'], df['Low'], df['Close'], length=14)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Create the Target Variable: Next Candle's Closing Price\n",
        "    # ------------------------------\n",
        "    # Shift the 'Close' column by -1 to get the next candle's closing price\n",
        "    df['Next_Close'] = df['Close'].shift(-1)\n",
        "\n",
        "    # Drop rows with any missing values generated by rolling calculations or shifting\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "8EO05PCugnuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_df = preprocess_crypto_df(df)\n",
        "featured_df = add_technical_features(preprocessed_df)\n",
        "# print(featured_df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eoF8bgCGh_GR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you have a DataFrame 'featured_df' that was returned from your add_technical_features() function.\n",
        "\n",
        "# Determine the index to split the data (80% training, 20% testing)\n",
        "train_size = int(0.8 * len(featured_df))\n",
        "\n",
        "# Create training and testing sets by slicing based on time order\n",
        "train_data = featured_df.iloc[:train_size]\n",
        "test_data = featured_df.iloc[train_size:]\n",
        "\n",
        "# Define the target variable (Next_Close) and feature columns.\n",
        "# Features: all columns except 'Next_Close'\n",
        "feature_cols = featured_df.columns.difference(['Next_Close']).tolist()\n",
        "\n",
        "# Split features (X) and target (y) for training and testing sets.\n",
        "X_train = train_data[feature_cols]\n",
        "y_train = train_data['Next_Close']\n",
        "X_test = test_data[feature_cols]\n",
        "y_test = test_data['Next_Close']\n",
        "\n",
        "# Print the shapes to verify the split\n",
        "print(\"Training set shape (features, target):\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape (features, target):\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0y9neR5irtq",
        "outputId": "68331b0f-f2f1-4020-de4a-04a8ec003e88"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape (features, target): (200554, 23) (200554,)\n",
            "Testing set shape (features, target): (50139, 23) (50139,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Random Forest Regressor\n",
        "# -----------------------------\n",
        "# Initialize the Random Forest model with a fixed random state for reproducibility.\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Train the model on the training data.\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable on the test set.\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance using:\n",
        "# - Mean Squared Error (MSE)\n",
        "# - Mean Absolute Error (MAE)\n",
        "# - R-squared (R²) score\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
        "rf_r2 = r2_score(y_test, rf_predictions)\n",
        "\n",
        "# Print out the performance metrics for Random Forest.\n",
        "print(\"Random Forest Performance:\")\n",
        "print(f\"Mean Squared Error: {rf_mse:.2f}\")\n",
        "print(f\"Mean Absolute Error: {rf_mae:.2f}\")\n",
        "print(f\"R-squared: {rf_r2:.2f}\")"
      ],
      "metadata": {
        "id": "d7jq9vVVm9xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# XGBoost Regressor\n",
        "# -----------------------------\n",
        "# Initialize the XGBoost model.\n",
        "# The 'reg:squarederror' objective is used for regression.\n",
        "# ----- -----------------------------------------------------------------------------------------\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Train the model on the training data.\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable on the test set.\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance using the same metrics as before.\n",
        "xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
        "xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
        "xgb_r2 = r2_score(y_test, xgb_predictions)\n",
        "\n",
        "# Print out the performance metrics for XGBoost.\n",
        "print(\"\\nXGBoost Performance:\")\n",
        "print(f\"Mean Squared Error: {xgb_mse:.2f}\")\n",
        "print(f\"Mean Absolute Error: {xgb_mae:.2f}\")\n",
        "print(f\"R-squared: {xgb_r2:.2f}\")"
      ],
      "metadata": {
        "id": "OnE0F_Pgok4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# Helper Function: Create Sequences for LSTM\n",
        "# --------------------------------------\n",
        "def create_sequences(X, y, seq_length):\n",
        "    \"\"\"\n",
        "    Create sequences of features and corresponding target values.\n",
        "\n",
        "    Parameters:\n",
        "      X (DataFrame): DataFrame containing feature data.\n",
        "      y (Series or array): Target variable (e.g., next candle's close price).\n",
        "      seq_length (int): Number of timesteps to include in each sequence.\n",
        "\n",
        "    Returns:\n",
        "      X_seq (numpy array): Array of shape (num_samples, seq_length, num_features)\n",
        "      y_seq (numpy array): Array of target values corresponding to each sequence.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    # Loop over the dataset to create sequences\n",
        "    for i in range(len(X) - seq_length):\n",
        "        # Extract a block of consecutive rows as one sequence\n",
        "        X_seq.append(X.iloc[i:i+seq_length].values)\n",
        "        # The target is the value right after this sequence\n",
        "        y_seq.append(y.iloc[i+seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# --------------------------------------\n",
        "# Step 1: Create Sequences for Training and Testing\n",
        "# --------------------------------------\n",
        "# Define the number of past timesteps to use as input (e.g., 10)\n",
        "sequence_length = 10\n",
        "\n",
        "# Build training sequences from your training set\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
        "# Build testing sequences from your test set\n",
        "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
        "\n",
        "# --------------------------------------\n",
        "# Step 2: Build the LSTM Model\n",
        "# --------------------------------------\n",
        "model = Sequential()\n",
        "\n",
        "# First LSTM layer with 50 units, returning sequences to stack another LSTM layer\n",
        "model.add(LSTM(50, activation='tanh', return_sequences=True, input_shape=(sequence_length, X_train_seq.shape[2])))\n",
        "model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
        "\n",
        "# Second LSTM layer to further capture temporal patterns\n",
        "model.add(LSTM(50, activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Final Dense layer to output the predicted next closing price\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model with Mean Squared Error loss and the Adam optimizer\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Print model summary to understand the architecture\n",
        "model.summary()\n",
        "\n",
        "# --------------------------------------\n",
        "# Step 3: Train the LSTM Model\n",
        "# --------------------------------------\n",
        "# Train the model on the training sequences. Here we use 20 epochs and a batch size of 32.\n",
        "history = model.fit(X_train_seq, y_train_seq, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# --------------------------------------\n",
        "# Step 4: Evaluate the Model\n",
        "# --------------------------------------\n",
        "# Predict the target on the test sequences\n",
        "lstm_predictions = model.predict(X_test_seq)\n",
        "\n",
        "# Calculate evaluation metrics: Mean Squared Error, Mean Absolute Error, and R-squared\n",
        "lstm_mse = mean_squared_error(y_test_seq, lstm_predictions)\n",
        "lstm_mae = mean_absolute_error(y_test_seq, lstm_predictions)\n",
        "lstm_r2 = r2_score(y_test_seq, lstm_predictions)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"LSTM Model Performance:\")\n",
        "print(f\"Mean Squared Error: {lstm_mse:.2f}\")\n",
        "print(f\"Mean Absolute Error: {lstm_mae:.2f}\")\n",
        "print(f\"R-squared: {lstm_r2:.2f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hZN7cTztyXiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}